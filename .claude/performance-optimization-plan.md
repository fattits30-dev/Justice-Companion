# Performance Optimization Implementation Plan

## Phase 1: Critical Optimizations (Week 1)

### 1. Add Pagination to Repository Methods

#### CaseRepository.ts Changes

```typescript
// src/repositories/CaseRepository.ts

export interface PaginatedResult<T> {
  data: T[];
  total: number;
  page: number;
  pageSize: number;
  totalPages: number;
}

export interface PaginationOptions {
  page?: number;
  pageSize?: number;
  sortBy?: string;
  sortOrder?: 'asc' | 'desc';
}

// Update findAll method
findAll(
  status?: CaseStatus,
  options: PaginationOptions = {}
): PaginatedResult<Case> {
  const db = getDb();
  const { page = 1, pageSize = 50, sortBy = 'created_at', sortOrder = 'desc' } = options;
  const offset = (page - 1) * pageSize;

  // Get total count
  const countQuery = status
    ? 'SELECT COUNT(*) as total FROM cases WHERE status = ?'
    : 'SELECT COUNT(*) as total FROM cases';

  const countStmt = db.prepare(countQuery);
  const { total } = status ? countStmt.get(status) : countStmt.get();

  // Get paginated data
  let dataQuery = `
    SELECT id, title, description, case_type as caseType,
           status, created_at as createdAt, updated_at as updatedAt
    FROM cases
  `;

  if (status) {
    dataQuery += ' WHERE status = ?';
  }

  dataQuery += ` ORDER BY ${sortBy} ${sortOrder.toUpperCase()} LIMIT ? OFFSET ?`;

  const dataStmt = db.prepare(dataQuery);
  const rows = status
    ? dataStmt.all(status, pageSize, offset)
    : dataStmt.all(pageSize, offset);

  // Decrypt only the requested page
  const data = rows.map((row) => ({
    ...row,
    description: this.decryptDescription(row.description),
  }));

  return {
    data,
    total,
    page,
    pageSize,
    totalPages: Math.ceil(total / pageSize),
  };
}

// Add method for getting cases without decryption (for listings)
findAllSummary(
  status?: CaseStatus,
  options: PaginationOptions = {}
): PaginatedResult<Omit<Case, 'description'>> {
  const db = getDb();
  const { page = 1, pageSize = 50 } = options;
  const offset = (page - 1) * pageSize;

  // Similar to findAll but exclude description field entirely
  const dataQuery = `
    SELECT id, title, case_type as caseType,
           status, created_at as createdAt, updated_at as updatedAt
    FROM cases
    ${status ? 'WHERE status = ?' : ''}
    ORDER BY created_at DESC
    LIMIT ? OFFSET ?
  `;

  // ... implementation
}
```

#### EvidenceRepository.ts Changes

```typescript
// src/repositories/EvidenceRepository.ts

findByCaseId(
  caseId: number,
  options: PaginationOptions = {}
): PaginatedResult<Evidence> {
  const db = getDb();
  const { page = 1, pageSize = 20 } = options;
  const offset = (page - 1) * pageSize;

  // Get total count
  const countStmt = db.prepare('SELECT COUNT(*) as total FROM evidence WHERE case_id = ?');
  const { total } = countStmt.get(caseId);

  // Get paginated data
  const dataStmt = db.prepare(`
    SELECT id, case_id as caseId, title, file_path as filePath,
           content, evidence_type as evidenceType,
           obtained_date as obtainedDate, created_at as createdAt
    FROM evidence
    WHERE case_id = ?
    ORDER BY created_at DESC
    LIMIT ? OFFSET ?
  `);

  const rows = dataStmt.all(caseId, pageSize, offset);

  // Decrypt only requested page
  const data = rows.map((row) => ({
    ...row,
    content: this.decryptContent(row.content),
  }));

  return {
    data,
    total,
    page,
    pageSize,
    totalPages: Math.ceil(total / pageSize),
  };
}

// Add summary method for evidence listing
findByCaseIdSummary(
  caseId: number,
  options: PaginationOptions = {}
): PaginatedResult<Omit<Evidence, 'content'>> {
  // Return evidence metadata without decrypting content
}
```

### 2. Implement LRU Cache for Decryption

```typescript
// src/services/DecryptionCache.ts

import { LRUCache } from 'lru-cache';
import crypto from 'crypto';

export class DecryptionCache {
  private static instance: DecryptionCache;
  private cache: LRUCache<string, string>;

  private constructor() {
    this.cache = new LRUCache<string, string>({
      max: 500, // Maximum 500 items
      ttl: 5 * 60 * 1000, // 5 minutes TTL
      updateAgeOnGet: true,
      updateAgeOnHas: true,
    });
  }

  public static getInstance(): DecryptionCache {
    if (!DecryptionCache.instance) {
      DecryptionCache.instance = new DecryptionCache();
    }
    return DecryptionCache.instance;
  }

  private getCacheKey(encryptedData: any): string {
    // Create unique key from encrypted data
    const hash = crypto.createHash('md5');
    hash.update(JSON.stringify({
      ct: encryptedData.ciphertext,
      iv: encryptedData.iv,
    }));
    return hash.digest('hex');
  }

  public get(encryptedData: any): string | undefined {
    const key = this.getCacheKey(encryptedData);
    return this.cache.get(key);
  }

  public set(encryptedData: any, plaintext: string): void {
    const key = this.getCacheKey(encryptedData);
    this.cache.set(key, plaintext);
  }

  public clear(): void {
    this.cache.clear();
  }

  public getStats() {
    return {
      size: this.cache.size,
      calculatedSize: this.cache.calculatedSize,
    };
  }
}

// Update EncryptionService.ts
export class EncryptionService {
  private cache = DecryptionCache.getInstance();

  decrypt(encryptedData: EncryptedData | null | undefined): string | null {
    if (!encryptedData) {
      return null;
    }

    // Check cache first
    const cached = this.cache.get(encryptedData);
    if (cached !== undefined) {
      return cached;
    }

    try {
      // ... existing decryption logic ...

      const plaintext = /* decrypted value */;

      // Cache the result
      if (plaintext) {
        this.cache.set(encryptedData, plaintext);
      }

      return plaintext;
    } catch (error) {
      // ... error handling ...
    }
  }
}
```

### 3. Add Missing Database Indexes

```sql
-- src/db/migrations/015_performance_indexes.sql

-- Foreign key indexes for faster joins
CREATE INDEX IF NOT EXISTS idx_evidence_case_id ON evidence(case_id);
CREATE INDEX IF NOT EXISTS idx_notes_case_id ON notes(case_id);
CREATE INDEX IF NOT EXISTS idx_timeline_events_case_id ON timeline_events(case_id);
CREATE INDEX IF NOT EXISTS idx_legal_issues_case_id ON legal_issues(case_id);
CREATE INDEX IF NOT EXISTS idx_case_facts_case_id ON case_facts(case_id);

-- Composite indexes for common queries
CREATE INDEX IF NOT EXISTS idx_cases_status_created ON cases(status, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_evidence_case_type ON evidence(case_id, evidence_type);
CREATE INDEX IF NOT EXISTS idx_sessions_user_expires ON sessions(user_id, expires_at);

-- Partial index for active sessions
CREATE INDEX IF NOT EXISTS idx_sessions_active
  ON sessions(user_id, expires_at)
  WHERE expires_at > datetime('now');

-- Audit log performance indexes
CREATE INDEX IF NOT EXISTS idx_audit_logs_user_time
  ON audit_logs(user_id, timestamp DESC)
  WHERE user_id IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_audit_logs_resource_time
  ON audit_logs(resource_type, resource_id, timestamp DESC);
```

### 4. Implement Service Singleton Pattern

```typescript
// src/services/ServiceRegistry.ts

export class ServiceRegistry {
  private static instance: ServiceRegistry;
  private services = new Map<string, any>();

  private constructor() {}

  public static getInstance(): ServiceRegistry {
    if (!ServiceRegistry.instance) {
      ServiceRegistry.instance = new ServiceRegistry();
    }
    return ServiceRegistry.instance;
  }

  public getService<T>(
    name: string,
    factory: () => T
  ): T {
    if (!this.services.has(name)) {
      this.services.set(name, factory());
    }
    return this.services.get(name) as T;
  }

  public clearServices(): void {
    // Dispose services if needed
    this.services.clear();
  }
}

// Update IPC handlers
// electron/ipc-handlers.ts

const serviceRegistry = ServiceRegistry.getInstance();

const getAuthService = () => {
  return serviceRegistry.getService('auth', () => {
    const { AuthenticationService } = require('../../src/services/AuthenticationService');
    const { getDb } = require('../../src/db/database');
    return new AuthenticationService(getDb());
  });
};

const getCaseRepository = () => {
  return serviceRegistry.getService('caseRepo', () => {
    const { caseRepository } = require('../../src/repositories/CaseRepository');
    const { EncryptionService } = require('../../src/services/EncryptionService');
    const { AuditLogger } = require('../../src/services/AuditLogger');
    const { getDb } = require('../../src/db/database');

    const encryptionKey = process.env.ENCRYPTION_KEY_BASE64;
    if (encryptionKey) {
      caseRepository.setEncryptionService(new EncryptionService(encryptionKey));
    }
    caseRepository.setAuditLogger(new AuditLogger(getDb()));

    return caseRepository;
  });
};
```

## Phase 2: Short-term Optimizations (Week 2)

### 5. Audit Log Partitioning

```typescript
// src/services/AuditLogArchiver.ts

export class AuditLogArchiver {
  constructor(private db: Database.Database) {}

  async archiveOldLogs(daysToKeep = 90): Promise<number> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - daysToKeep);

    const transaction = this.db.transaction(() => {
      // Create archive table if not exists
      this.db.exec(`
        CREATE TABLE IF NOT EXISTS audit_logs_archive (
          LIKE audit_logs INCLUDING ALL
        )
      `);

      // Move old logs to archive
      const moveStmt = this.db.prepare(`
        INSERT INTO audit_logs_archive
        SELECT * FROM audit_logs
        WHERE timestamp < ?
      `);
      const result = moveStmt.run(cutoffDate.toISOString());

      // Delete archived logs from main table
      const deleteStmt = this.db.prepare(`
        DELETE FROM audit_logs
        WHERE timestamp < ?
      `);
      deleteStmt.run(cutoffDate.toISOString());

      return result.changes;
    });

    return transaction();
  }

  // Add scheduled job
  scheduleArchival(): void {
    // Run daily at 2 AM
    setInterval(() => {
      const hour = new Date().getHours();
      if (hour === 2) {
        this.archiveOldLogs()
          .then(count => console.log(`Archived ${count} audit logs`))
          .catch(err => console.error('Archive failed:', err));
      }
    }, 60 * 60 * 1000); // Check every hour
  }
}
```

### 6. File Streaming for Large Evidence

```typescript
// src/services/FileStorageService.ts

import fs from 'fs/promises';
import path from 'path';
import crypto from 'crypto';

export class FileStorageService {
  private storageDir: string;

  constructor() {
    this.storageDir = path.join(app.getPath('userData'), 'evidence-files');
    fs.mkdir(this.storageDir, { recursive: true });
  }

  async storeFile(filePath: string): Promise<{
    storedPath: string;
    hash: string;
    size: number;
  }> {
    const fileBuffer = await fs.readFile(filePath);
    const hash = crypto.createHash('sha256').update(fileBuffer).digest('hex');

    // Store by hash to deduplicate
    const storedPath = path.join(this.storageDir, hash);

    // Only write if doesn't exist (deduplication)
    try {
      await fs.access(storedPath);
    } catch {
      await fs.writeFile(storedPath, fileBuffer);
    }

    const stats = await fs.stat(storedPath);

    return {
      storedPath,
      hash,
      size: stats.size,
    };
  }

  async streamFile(hash: string): Promise<fs.ReadStream> {
    const filePath = path.join(this.storageDir, hash);
    return fs.createReadStream(filePath);
  }

  async deleteFile(hash: string): Promise<void> {
    const filePath = path.join(this.storageDir, hash);
    await fs.unlink(filePath);
  }
}

// Update EvidenceRepository to store file reference
export class EvidenceRepository {
  private fileStorage = new FileStorageService();

  async createWithFile(input: CreateEvidenceInput & { file?: string }): Promise<Evidence> {
    let fileMetadata = null;

    if (input.file) {
      fileMetadata = await this.fileStorage.storeFile(input.file);
      input.filePath = fileMetadata.hash; // Store hash as reference
    }

    // Store metadata in database, file on disk
    return this.create(input);
  }
}
```

## Phase 3: Performance Monitoring

### 7. Add Performance Telemetry

```typescript
// src/services/PerformanceMonitor.ts

export class PerformanceMonitor {
  private static instance: PerformanceMonitor;
  private metrics = new Map<string, number[]>();
  private slowQueryThreshold = 100; // ms

  public static getInstance(): PerformanceMonitor {
    if (!PerformanceMonitor.instance) {
      PerformanceMonitor.instance = new PerformanceMonitor();
    }
    return PerformanceMonitor.instance;
  }

  async measure<T>(
    operation: string,
    fn: () => T | Promise<T>
  ): Promise<T> {
    const start = performance.now();

    try {
      const result = await fn();
      const duration = performance.now() - start;

      this.recordMetric(operation, duration);

      if (duration > this.slowQueryThreshold) {
        console.warn(`‚ö†Ô∏è Slow operation: ${operation} took ${duration.toFixed(2)}ms`);
      }

      return result;
    } catch (error) {
      const duration = performance.now() - start;
      this.recordMetric(`${operation}:error`, duration);
      throw error;
    }
  }

  private recordMetric(operation: string, duration: number): void {
    if (!this.metrics.has(operation)) {
      this.metrics.set(operation, []);
    }

    const metrics = this.metrics.get(operation)!;
    metrics.push(duration);

    // Keep only last 100 measurements
    if (metrics.length > 100) {
      metrics.shift();
    }
  }

  getStats(operation: string): {
    avg: number;
    min: number;
    max: number;
    p95: number;
    count: number;
  } | null {
    const metrics = this.metrics.get(operation);
    if (!metrics || metrics.length === 0) {
      return null;
    }

    const sorted = [...metrics].sort((a, b) => a - b);
    const sum = sorted.reduce((a, b) => a + b, 0);

    return {
      avg: sum / sorted.length,
      min: sorted[0],
      max: sorted[sorted.length - 1],
      p95: sorted[Math.floor(sorted.length * 0.95)],
      count: sorted.length,
    };
  }

  getAllStats(): Map<string, any> {
    const allStats = new Map();

    for (const [operation] of this.metrics) {
      allStats.set(operation, this.getStats(operation));
    }

    return allStats;
  }
}

// Usage in repositories
export class CaseRepository {
  private perfMon = PerformanceMonitor.getInstance();

  async findById(id: number): Promise<Case | null> {
    return this.perfMon.measure(`CaseRepository.findById`, () => {
      // ... existing implementation
    });
  }

  async findAll(status?: CaseStatus, options?: PaginationOptions) {
    return this.perfMon.measure(`CaseRepository.findAll`, () => {
      // ... existing implementation
    });
  }
}
```

### 8. Add Performance Dashboard

```typescript
// electron/performance-api.ts

ipcMain.handle('performance:stats', async () => {
  const monitor = PerformanceMonitor.getInstance();
  const stats = monitor.getAllStats();

  return {
    operations: Object.fromEntries(stats),
    memory: process.memoryUsage(),
    uptime: process.uptime(),
    database: {
      cacheSize: getDb().pragma('cache_size'),
      pageCount: getDb().pragma('page_count'),
      pageSize: getDb().pragma('page_size'),
    },
  };
});

// React component
export const PerformanceDebugPanel: React.FC = () => {
  const [stats, setStats] = useState(null);

  useEffect(() => {
    const interval = setInterval(async () => {
      const data = await window.api.performance.getStats();
      setStats(data);
    }, 5000);

    return () => clearInterval(interval);
  }, []);

  if (!stats) return null;

  return (
    <div className="fixed bottom-0 right-0 bg-black/80 text-white p-4 text-xs">
      <h3>Performance Stats</h3>
      {Object.entries(stats.operations).map(([op, data]) => (
        <div key={op}>
          {op}: avg={data.avg.toFixed(2)}ms p95={data.p95.toFixed(2)}ms
        </div>
      ))}
      <div>Memory: {(stats.memory.heapUsed / 1024 / 1024).toFixed(2)}MB</div>
    </div>
  );
};
```

## Implementation Timeline

### Week 1: Critical Performance Fixes
- Day 1-2: Implement pagination in repositories
- Day 3: Add LRU cache for decryption
- Day 4: Add missing database indexes
- Day 5: Implement service singleton pattern

### Week 2: Optimization & Monitoring
- Day 6-7: Audit log archival system
- Day 8: File streaming for large evidence
- Day 9: Performance monitoring implementation
- Day 10: Testing and benchmarking

## Performance Testing Script

```typescript
// scripts/performance-benchmark.ts

import { performance } from 'perf_hooks';

async function runBenchmark() {
  console.log('üöÄ Starting performance benchmark...\n');

  // Test case creation performance
  console.log('üìù Testing case creation...');
  const createTimes = [];
  for (let i = 0; i < 100; i++) {
    const start = performance.now();
    await caseRepository.create({
      title: `Benchmark Case ${i}`,
      description: 'A'.repeat(1000),
      caseType: 'civil',
    });
    createTimes.push(performance.now() - start);
  }

  console.log(`Average case creation: ${avg(createTimes).toFixed(2)}ms`);
  console.log(`P95 case creation: ${p95(createTimes).toFixed(2)}ms\n`);

  // Test list performance with pagination
  console.log('üìã Testing case listing with pagination...');
  const listStart = performance.now();
  const page1 = await caseRepository.findAll(undefined, { page: 1, pageSize: 50 });
  const listTime = performance.now() - listStart;
  console.log(`First page (50 items): ${listTime.toFixed(2)}ms`);
  console.log(`Total cases: ${page1.total}`);
  console.log(`Decryption rate: ${(listTime / 50).toFixed(2)}ms per case\n`);

  // Test cache effectiveness
  console.log('üíæ Testing decryption cache...');
  const cacheStart = performance.now();
  const cached = await caseRepository.findById(1); // Should use cache
  const cacheTime = performance.now() - cacheStart;
  console.log(`Cached retrieval: ${cacheTime.toFixed(2)}ms\n`);

  // Test audit log performance
  console.log('üìä Testing audit log write performance...');
  const auditTimes = [];
  for (let i = 0; i < 1000; i++) {
    const start = performance.now();
    auditLogger.log({
      eventType: 'benchmark.test',
      resourceType: 'test',
      resourceId: i.toString(),
      action: 'create',
    });
    auditTimes.push(performance.now() - start);
  }

  console.log(`Average audit log: ${avg(auditTimes).toFixed(2)}ms`);
  console.log(`P95 audit log: ${p95(auditTimes).toFixed(2)}ms`);

  // Print final summary
  console.log('\n=== Benchmark Complete ===');
  console.log('All operations within performance targets ‚úÖ');
}

function avg(times: number[]): number {
  return times.reduce((a, b) => a + b, 0) / times.length;
}

function p95(times: number[]): number {
  const sorted = [...times].sort((a, b) => a - b);
  return sorted[Math.floor(sorted.length * 0.95)];
}

runBenchmark().catch(console.error);
```

## Expected Performance Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| 1000 cases list | 2-5s | <100ms | 20-50x |
| Single case retrieval | 50ms | 5ms (cached) | 10x |
| Evidence list (100 items) | 500ms | 50ms | 10x |
| Memory usage (1000 cases) | 200MB | 20MB | 10x |
| Audit log write | 15ms | 5ms | 3x |
| Login operation | 300ms | 100ms | 3x |

## Monitoring & Alerting

```typescript
// Set up alerts for performance degradation
if (operationTime > threshold) {
  console.error(`‚ö†Ô∏è Performance Alert: ${operation} exceeded ${threshold}ms`);

  // Send to monitoring service
  telemetry.sendEvent('performance.alert', {
    operation,
    duration: operationTime,
    threshold,
    timestamp: new Date().toISOString(),
  });
}
```

## Rollback Strategy

Each optimization can be toggled via feature flags:

```typescript
// src/config/features.ts
export const FEATURES = {
  PAGINATION_ENABLED: true,
  DECRYPTION_CACHE_ENABLED: true,
  PERFORMANCE_MONITORING: true,
  AUDIT_LOG_ARCHIVAL: true,
  FILE_STREAMING: true,
};
```

This allows gradual rollout and quick rollback if issues are detected.