[{"filePath":"C:\\Users\\sava6\\Desktop\\Justice Companion\\src\\features\\chat\\services\\IntegratedAIService.ts","messages":[{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":52,"column":52,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":52,"endColumn":54,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[1520,1522],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":91,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":91,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":91,"column":30,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":91,"endColumn":33},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":94,"column":18,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":94,"endColumn":20,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[2669,2671],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":110,"column":46,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":110,"endColumn":48,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[3218,3220],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":114,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":118,"endColumn":9},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":114,"column":26,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":114,"endColumn":46},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .loadModel on an `any` value.","line":114,"column":37,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":114,"endColumn":46},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":123,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":123,"endColumn":68},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access ._trainContextSize on an `any` value.","line":123,"column":42,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":123,"endColumn":59},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":123,"column":60,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":123,"endColumn":62,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[3876,3878],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":130,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":130,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[4325,4327],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":138,"column":42,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":138,"endColumn":44,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[4602,4604],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":142,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":145,"endColumn":9},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":142,"column":28,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":142,"endColumn":52},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .createContext on an `any` value.","line":142,"column":39,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":142,"endColumn":52},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":149,"column":25,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":149,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-argument","severity":1,"message":"Unsafe argument of type `any` assigned to a parameter of type `LegalContext`.","line":252,"column":43,"nodeType":"Identifier","messageId":"unsafeArgument","endLine":252,"endColumn":50},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":379,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":379,"endColumn":51},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":379,"column":25,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":379,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .getSequence on an `any` value.","line":379,"column":38,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":379,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":383,"column":9,"nodeType":"Property","messageId":"anyAssignment","endLine":383,"endColumn":24},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":393,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":393,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[13144,13146],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":401,"column":25,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":401,"endColumn":28},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??=`) instead of an assignment expression, as it is simpler to read.","line":417,"column":11,"nodeType":"IfStatement","messageId":"preferNullishOverAssignment","endLine":419,"endColumn":12,"suggestions":[{"messageId":"suggestNullish","data":{"equals":"="},"fix":{"range":[13929,14012],"text":"firstTokenTime ??= Date.now();"},"desc":"Fix to nullish coalescing operator (`??=`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":435,"column":62,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":435,"endColumn":64,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[14606,14608],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":441,"column":66,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":441,"endColumn":68,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[14826,14828],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":485,"column":13,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":485,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":485,"column":29,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":485,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":499,"column":17,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":499,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":499,"column":33,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":499,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":563,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":563,"endColumn":51},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":563,"column":25,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":563,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .getSequence on an `any` value.","line":563,"column":38,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":563,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":567,"column":9,"nodeType":"Property","messageId":"anyAssignment","endLine":567,"endColumn":24},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":575,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":575,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[19390,19392],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??=`) instead of an assignment expression, as it is simpler to read.","line":592,"column":11,"nodeType":"IfStatement","messageId":"preferNullishOverAssignment","endLine":594,"endColumn":12,"suggestions":[{"messageId":"suggestNullish","data":{"equals":"="},"fix":{"range":[20130,20213],"text":"firstTokenTime ??= Date.now();"},"desc":"Fix to nullish coalescing operator (`??=`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":601,"column":13,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":601,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":601,"column":29,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":601,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":614,"column":17,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":614,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":614,"column":33,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":614,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":654,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":654,"endColumn":35},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":654,"column":28,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":654,"endColumn":35},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":658,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":658,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":658,"column":26,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":658,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":662,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":662,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":662,"column":26,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":662,"endColumn":33}],"suppressedMessages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":38,"column":18,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":38,"endColumn":21,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[908,911],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[908,911],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":39,"column":18,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":39,"endColumn":21,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[970,973],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[970,973],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":40,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":40,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1030,1033],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1030,1033],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":176,"column":42,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":176,"endColumn":45,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5808,5811],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5808,5811],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":360,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":360,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11967,11970],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11967,11970],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":531,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":531,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[17879,17882],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[17879,17882],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]}],"errorCount":0,"fatalErrorCount":0,"warningCount":47,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { errorLogger } from '../../../utils/error-logger';\nimport {\n  DEFAULT_AI_CONFIG,\n  buildSystemPrompt,\n  extractSources,\n} from '../../../types/ai';\nimport type {\n  AIConfig,\n  AIStatus,\n  AIChatRequest,\n  AIResponse,\n} from '../../../types/ai';\nimport path from 'path';\nimport { app } from 'electron';\nimport os from 'os';\n\n/**\n * IntegratedAIService - Sovereign AI using node-llama-cpp\n *\n * Runs Qwen 3 8B locally with AMD Vulkan GPU acceleration.\n * No external dependencies - complete sovereignty.\n */\n// Use eslint-disable for node-llama-cpp types (external library with complex types)\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\ninterface CaseFactsRepository {\n  findByCaseId(caseId: number): CaseFact[];\n}\n\ninterface CaseFact {\n  factContent: string;\n  factCategory: string;\n  importance: string;\n}\n\nexport class IntegratedAIService {\n  private config: AIConfig;\n  private llama: any = null; // node-llama-cpp Llama instance\n  private model: any = null; // node-llama-cpp LlamaModel\n  private context: any = null; // node-llama-cpp LlamaContext\n  private isInitialized = false;\n  private modelFileName = 'Qwen_Qwen3-8B-Q4_K_M.gguf';\n  private modelPath: string;\n  private caseFactsRepository: CaseFactsRepository | null = null; // Optional dependency for fact loading\n\n  constructor(config?: Partial<AIConfig>, caseFactsRepository?: CaseFactsRepository) {\n    this.config = {\n      ...DEFAULT_AI_CONFIG,\n      ...config,\n    } as AIConfig;\n\n    this.caseFactsRepository = caseFactsRepository || null;\n\n    // Model storage: app.getPath('userData')/models/\n    const userDataPath = app.getPath('userData');\n    this.modelPath = path.join(userDataPath, 'models', this.modelFileName);\n\n    errorLogger.logError('IntegratedAIService initialized', {\n      type: 'info',\n      modelPath: this.modelPath,\n    });\n  }\n\n  /**\n   * Initialize node-llama-cpp and load Qwen 3 8B model\n   * Uses dynamic import() for ESM compatibility\n   */\n  async initialize(): Promise<void> {\n    if (this.isInitialized) {\n      return;\n    }\n\n    try {\n      errorLogger.logError('Loading node-llama-cpp (ESM dynamic import)', {\n        type: 'info',\n      });\n\n      // Dynamic import for ESM module\n      const { getLlama, LlamaLogLevel } = await import('node-llama-cpp');\n\n      errorLogger.logError('Initializing Llama with AMD GPU detection', {\n        type: 'info',\n      });\n\n      // Initialize with AMD Vulkan GPU auto-detection\n      this.llama = await getLlama({\n        logLevel: LlamaLogLevel.warn,\n      });\n\n      // Log detected GPU\n      const gpu = this.llama.gpu;\n      errorLogger.logError('GPU detected', {\n        type: 'info',\n        gpu: gpu || 'CPU only',\n      });\n\n      errorLogger.logError('Loading Qwen 3 8B model', {\n        type: 'info',\n        modelPath: this.modelPath,\n      });\n\n      // Auto-detect optimal CPU threads (use 75% of available cores for responsiveness)\n      const cpuCores = os.cpus().length;\n      const optimalThreads = this.config.threads ?? Math.max(1, Math.floor(cpuCores * 0.75));\n\n      errorLogger.logError('Hardware auto-detection complete', {\n        type: 'info',\n        cpuCores,\n        optimalThreads,\n        contextSize: this.config.contextSize || 4096,\n      });\n\n      // Load model with AMD GPU acceleration (37/37 layers - full GPU offload for 8GB VRAM)\n      this.model = await this.llama.loadModel({\n        modelPath: this.modelPath,\n        gpuLayers: 'max', // All layers on GPU (8GB VRAM available)\n        defaultContextFlashAttention: true, // Flash Attention for memory efficiency\n      });\n\n      // Auto-detect context size from model capabilities with VRAM awareness\n      // For 8GB VRAM: Model (~4.5GB) + KV cache + overhead = safe limit ~16K tokens\n      // For 16GB+ VRAM: Can use 90% of model's max (29,491 for 32K models)\n      const modelMaxContext = this.model._trainContextSize || 32768;\n\n      // Conservative context for 8GB VRAM (tested on AMD RX 6600 8GB)\n      // This ensures model + KV cache fit comfortably in VRAM\n      // Tested: 16K failed (VRAM overflow), 12K works perfectly\n      const safeContextFor8GB = 12288; // 12K tokens = ~9,000 words (ideal for legal documents)\n      const optimalContext = Math.min(safeContextFor8GB, Math.floor(modelMaxContext * 0.9));\n      const contextSize = this.config.contextSize || optimalContext;\n\n      errorLogger.logError(`Creating context (${contextSize} tokens with Flash Attention)`, {\n        type: 'info',\n        modelMaxContext,\n        optimalContext,\n        contextSize,\n        flashAttention: true,\n        batchSize: this.config.batchSize || 'auto',\n      });\n\n      // Create context for legal document analysis with Flash Attention\n      this.context = await this.model.createContext({\n        contextSize, // Auto-detected from model (90% of 32,768 = 29,491 tokens)\n        ...(this.config.batchSize && { batchSize: this.config.batchSize }), // Optional batch size optimization\n      });\n\n      errorLogger.logError('IntegratedAIService fully initialized', {\n        type: 'info',\n        gpu: this.llama.gpu,\n        cpuCores,\n        threads: optimalThreads,\n        contextSize,\n        flashAttention: true,\n        gpuLayers: '37/37 (max)',\n      });\n\n      this.isInitialized = true;\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      this.isInitialized = false;\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.initialize',\n      });\n\n      throw new Error(`Failed to initialize Integrated AI: ${errorMessage}`);\n    }\n  }\n\n  /**\n   * Get Qwen 3 optimized system prompt with fact-gathering rules\n   * Qwen 3 supports <think> tags for reasoning and [[call: function()]] for tool use\n   */\n  private getQwen3SystemPrompt(context?: any, facts?: CaseFact[]): string {\n    // Build base prompt with fact-gathering rules\n    const basePrompt = `You are a UK legal information assistant with ADMINISTRATIVE POWERS.\n\nðŸ”’ HARD-CODED RULES (NEVER BREAK):\n\nRULE 0: FIRST-TIME USER ONBOARDING (HIGHEST PRIORITY)\n- If user responds to welcome questions with personal info or their issue:\n  âœ“ Extract name/email and call update_user_profile immediately\n  âœ“ Extract issue description and store as case fact using store_case_fact\n  âœ“ Thank them warmly for sharing their situation\n  âœ“ Ask 2-3 specific follow-up questions to gather MORE details about their case\n- Example: User says \"My name is John and I was unfairly dismissed\"\n  â†’ Call: update_user_profile({name: \"John\"})\n  â†’ Call: store_case_fact({factType: \"issue\", factKey: \"case_type\", factValue: \"unfair dismissal\", confidence: 1.0})\n  â†’ Respond: \"Thank you for sharing, John. I'm here to help with your dismissal case. Can you tell me: when did this happen, who was your employer, and did you receive any written notice?\"\n\nRULE 1: FACT-GATHERING IS MANDATORY\n- When working on a case with <3 stored facts, you are in FACT-GATHERING MODE\n- You MUST gather these facts BEFORE providing legal information:\n  âœ“ Party names (employee, employer, witnesses)\n  âœ“ Key dates (employment start, dismissal date, deadlines)\n  âœ“ Event sequence (what happened, when, why)\n  âœ“ Evidence available (contracts, emails, witnesses)\n\nRULE 2: STORE FACTS IMMEDIATELY\n- As user provides information, extract facts and store them using store_case_fact\n- Format: [[call: store_case_fact({caseId: 42, factType: \"timeline\", factKey: \"dismissal_date\", factValue: \"2024-01-15\", confidence: 1.0})]]\n- Store facts for: parties (witness), dates (timeline), events (timeline), evidence (evidence), locations (location), communications (communication)\n\nRULE 3: FACTS ARE YOUR ANCHOR\n- Before EVERY response about a case, load facts using get_case_facts\n- Format: [[call: get_case_facts({caseId: 42})]]\n- Reference specific stored facts in your response to show you remember\n\nREASONING INSTRUCTIONS:\n- Use <think>reasoning</think> tags for complex analysis\n- Inside <think>: analyze question, check facts, plan response\n- User will NOT see <think> content\n\nEMPATHETIC COMMUNICATION:\n- Acknowledge their situation warmly\n- Use supportive phrases: \"I understand this must be...\", \"That's a great question...\"\n- Be conversational, not clinical\n- Validate concerns before explaining law\n\nPROFESSIONAL STANDARDS:\n- Provide legal INFORMATION, NOT legal advice\n- Cite sources precisely (e.g., \"Employment Rights Act 1996 Section 94\")\n- Ask clarifying questions if needed\n- Never give blunt \"I don't have information\"\n\nTONE EXAMPLES:\nâœ“ \"I understand this is stressful. Let me explain unfair dismissal law...\"\nâœ“ \"Great question. The Employment Rights Act 1996 states...\"\nâœ— \"Query processed. ERA 1996 S94 states...\"\nâœ— \"I don't have that information.\"\n\nFormat for citations:\n- Legislation: \"Section X of the [Act Name] [Year]\"\n- Case law: \"[Case Name] [Year] [Court]\"`;\n\n    // If we have stored facts, append them to the prompt\n    if (facts && facts.length > 0) {\n      const factsSection = `\n\nðŸ“‹ STORED FACTS FOR THIS CASE:\n${facts.map((f) => `- ${f.factContent} [${f.factCategory}, ${f.importance} importance]`).join('\\n')}\n\nUse these facts as your memory. Reference them in your responses.`;\n\n      return basePrompt + factsSection;\n    }\n\n    // If we have RAG context, use buildSystemPrompt but inject fact-gathering rules\n    if (context) {\n      const ragPrompt = buildSystemPrompt(context);\n      // Prepend fact-gathering rules to RAG prompt\n      return basePrompt + '\\n\\n--- RAG CONTEXT ---\\n' + ragPrompt;\n    }\n\n    return basePrompt;\n  }\n\n  /**\n   * Check if Integrated AI is ready\n   */\n  async checkConnection(): Promise<AIStatus> {\n    try {\n      // If not initialized, try to initialize\n      if (!this.isInitialized) {\n        await this.initialize();\n      }\n\n      return {\n        connected: true,\n        endpoint: 'Integrated AI (Qwen 3 8B)',\n        model: this.modelFileName,\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      return {\n        connected: false,\n        endpoint: 'Integrated AI (Qwen 3 8B)',\n        error: errorMessage,\n      };\n    }\n  }\n\n  /**\n   * Non-streaming chat (converts streaming to single response)\n   */\n  async chat(request: AIChatRequest): Promise<AIResponse> {\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n      if (!status.connected) {\n        return {\n          success: false,\n          error: `Integrated AI not ready: ${status.error}`,\n          code: 'INTEGRATED_AI_OFFLINE',\n        };\n      }\n\n      let fullResponse = '';\n      const sources: string[] = [];\n\n      // Use streaming internally\n      await this.streamChat(\n        request,\n        (token) => {\n          fullResponse += token;\n        },\n        () => {\n          // Complete\n        },\n        (error) => {\n          throw new Error(error);\n        },\n        undefined, // No think tokens needed for non-streaming\n        (extractedSources) => {\n          sources.push(...extractedSources);\n        },\n      );\n\n      return {\n        success: true,\n        message: {\n          role: 'assistant',\n          content: fullResponse,\n          timestamp: new Date().toISOString(),\n        },\n        sources,\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.chat',\n      });\n\n      return {\n        success: false,\n        error: errorMessage,\n        code: 'EXCEPTION',\n      };\n    }\n  }\n\n  /**\n   * Streaming chat with Qwen 3 8B\n   * Maintains exact same interface as AIService\n   */\n  async streamChat(\n    request: AIChatRequest,\n    onToken: (token: string) => void,\n    onComplete: () => void,\n    onError: (error: string) => void,\n    onThinkToken?: (token: string) => void,\n    onSources?: (sources: string[]) => void,\n  ): Promise<void> {\n    let contextSequence: any = null; // node-llama-cpp LlamaContextSequence\n\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n\n      if (!status.connected) {\n        onError(`Integrated AI not ready: ${status.error}`);\n        return;\n      }\n\n      // Import session class\n      const { LlamaChatSession } = await import('node-llama-cpp');\n\n      // Build system prompt\n      const systemPrompt = this.getQwen3SystemPrompt(request.context);\n\n      // Create FRESH sequence that will be disposed after use\n      // This prevents KV cache accumulation and VRAM overflow\n      contextSequence = this.context.getSequence();\n\n      // Create chat session with fresh sequence\n      const chatSession = new LlamaChatSession({\n        contextSequence,\n        systemPrompt,\n      });\n\n      // Get ONLY the most recent user message (not full history)\n      // UI maintains conversation history - we just process latest question\n      // This keeps context size constant: system prompt + latest question\n      const lastUserMessage = [...request.messages]\n        .reverse()\n        .find((msg) => msg.role === 'user');\n      const userPrompt = lastUserMessage?.content || '';\n\n      if (!userPrompt) {\n        throw new Error('No user message found in request');\n      }\n\n      errorLogger.logError('Starting Qwen 3 8B streaming inference', {\n        type: 'info',\n        gpu: this.llama.gpu,\n      });\n\n      let accumulatedContent = '';\n      let insideThinkTag = false;\n      let thinkBuffer = '';\n      let tokenCount = 0;\n      const startTime = Date.now();\n      let firstTokenTime: number | null = null;\n\n      // Stream tokens\n      await chatSession.prompt(userPrompt.trim(), {\n        temperature: request.config?.temperature ?? this.config.temperature,\n        maxTokens: request.config?.maxTokens ?? this.config.maxTokens,\n        onTextChunk: (chunk: string) => {\n          // Record time of first token (after prompt processing)\n          if (firstTokenTime === null) {\n            firstTokenTime = Date.now();\n          }\n\n          tokenCount++;\n          // Process chunk for <think> tag filtering\n          thinkBuffer += chunk;\n\n          // Check for tag transitions\n          if (thinkBuffer.includes('<think>')) {\n            insideThinkTag = true;\n            // Extract content before tag and send it\n            const beforeTag = thinkBuffer.split('<think>')[0];\n            if (beforeTag) {\n              onToken(beforeTag);\n              accumulatedContent += beforeTag;\n            }\n            // Keep content after tag for next iteration\n            thinkBuffer = thinkBuffer.split('<think>').pop() || '';\n          }\n\n          if (thinkBuffer.includes('</think>')) {\n            insideThinkTag = false;\n            // Extract content after closing tag\n            const afterTag = thinkBuffer.split('</think>').pop() || '';\n            thinkBuffer = afterTag;\n          }\n\n          // Send token based on context\n          if (insideThinkTag) {\n            // Send think content to onThinkToken callback if provided\n            if (thinkBuffer && onThinkToken) {\n              onThinkToken(thinkBuffer);\n              thinkBuffer = '';\n            }\n          } else if (thinkBuffer) {\n            // Send display content to onToken callback\n            onToken(thinkBuffer);\n            accumulatedContent += thinkBuffer;\n            thinkBuffer = '';\n          }\n        },\n      });\n\n      // Calculate performance stats\n      const endTime = Date.now();\n      const totalDuration = (endTime - startTime) / 1000;\n      const generationTime = firstTokenTime ? (endTime - firstTokenTime) / 1000 : totalDuration;\n      const generationSpeed = generationTime > 0 ? tokenCount / generationTime : 0;\n\n      // Extract sources after completion\n      if (request.context && onSources && accumulatedContent) {\n        const sources = extractSources(accumulatedContent, request.context);\n        errorLogger.logError('Sources extracted from Qwen 3 response', {\n          type: 'info',\n          sourcesCount: sources.length,\n        });\n        onSources(sources);\n      }\n\n      errorLogger.logError('Qwen 3 8B streaming complete', {\n        type: 'info',\n        tokenCount,\n        totalDuration: totalDuration.toFixed(2),\n        generationSpeed: generationSpeed.toFixed(2),\n      });\n\n      // CRITICAL: Dispose sequence to clear KV cache and prevent VRAM accumulation\n      await contextSequence.dispose();\n\n      onComplete();\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.streamChat',\n      });\n\n      // Clean up sequence even on error (if it was created)\n      if (contextSequence) {\n        try {\n          await contextSequence.dispose();\n        } catch (disposeError) {\n          errorLogger.logError(disposeError as Error, {\n            context: 'Failed to dispose sequence after error',\n          });\n        }\n      }\n\n      onError(errorMessage);\n    }\n  }\n\n  /**\n   * Streaming chat with Qwen 3 8B + Function Calling\n   *\n   * This method enables AI to call functions like store_case_fact and get_case_facts.\n   * Uses node-llama-cpp's built-in function calling with LlamaChatSession.\n   * Functions are automatically executed when AI uses [[call: function()]] syntax.\n   *\n   * @param request - Chat request with messages and context\n   * @param caseId - Optional case ID for fact loading/storing\n   * @param onToken - Callback for each token generated\n   * @param onComplete - Callback when streaming completes\n   * @param onError - Callback for errors\n   */\n  async streamChatWithFunctions(\n    request: AIChatRequest,\n    caseId: number | undefined,\n    onToken: (token: string) => void,\n    onComplete: () => void,\n    onError: (error: string) => void,\n  ): Promise<void> {\n    let contextSequence: any = null; // node-llama-cpp LlamaContextSequence\n\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n      if (!status.connected) {\n        onError(`Integrated AI not ready: ${status.error}`);\n        return;\n      }\n\n      // Load facts if caseId provided (for system prompt injection)\n      let facts: CaseFact[] = [];\n      if (caseId && this.caseFactsRepository) {\n        try {\n          facts = this.caseFactsRepository.findByCaseId(caseId);\n        } catch (error) {\n          errorLogger.logError(error as Error, {\n            context: 'Failed to load facts for AI context',\n            caseId,\n          });\n          // Continue with empty facts - don't fail the entire request\n        }\n      }\n\n      // Import required classes\n      const { LlamaChatSession } = await import('node-llama-cpp');\n      const { aiFunctions } = await import('../../../services/ai-functions.js');\n\n      // Build system prompt with facts\n      const systemPrompt = this.getQwen3SystemPrompt(request.context, facts);\n\n      // Create fresh sequence\n      contextSequence = this.context.getSequence();\n\n      // Create chat session with function calling enabled\n      const chatSession = new LlamaChatSession({\n        contextSequence,\n        systemPrompt,\n      });\n\n      // Get only the most recent user message\n      const lastUserMessage = [...request.messages]\n        .reverse()\n        .find((msg) => msg.role === 'user');\n      const userPrompt = lastUserMessage?.content || '';\n\n      if (!userPrompt) {\n        throw new Error('No user message found in request');\n      }\n\n      let _tokenCount = 0;\n      let firstTokenTime: number | null = null;\n\n      // Stream with function calling enabled\n      // Note: node-llama-cpp automatically executes functions when AI uses [[call: function()]] syntax\n      // Function results are automatically sent back to AI as [[result: {...}]]\n      await chatSession.prompt(userPrompt.trim(), {\n        temperature: request.config?.temperature ?? this.config.temperature,\n        maxTokens: request.config?.maxTokens ?? this.config.maxTokens,\n        functions: aiFunctions, // ðŸ”¥ Enable function calling (auto-executed)\n        onTextChunk: (chunk: string) => {\n          if (firstTokenTime === null) {\n            firstTokenTime = Date.now();\n          }\n          _tokenCount++;\n          onToken(chunk);\n        },\n      });\n\n      // Dispose sequence\n      await contextSequence.dispose();\n\n      onComplete();\n    } catch (error) {\n      const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.streamChatWithFunctions',\n      });\n\n      // Clean up sequence on error\n      if (contextSequence) {\n        try {\n          await contextSequence.dispose();\n        } catch (disposeError) {\n          errorLogger.logError(disposeError as Error, {\n            context: 'Failed to dispose sequence after error in streamChatWithFunctions',\n          });\n        }\n      }\n\n      onError(errorMessage);\n    }\n  }\n\n  /**\n   * Update configuration\n   */\n  updateConfig(config: Partial<AIConfig>): void {\n    this.config = {\n      ...this.config,\n      ...config,\n    };\n\n    errorLogger.logError('Integrated AI configuration updated', {\n      type: 'info',\n      config: this.config,\n    });\n  }\n\n  /**\n   * Get current configuration\n   */\n  getConfig(): AIConfig {\n    return { ...this.config };\n  }\n\n  /**\n   * Cleanup resources\n   */\n  async dispose(): Promise<void> {\n    try {\n      if (this.context) {\n        await this.context.dispose();\n        this.context = null;\n      }\n      if (this.model) {\n        await this.model.dispose();\n        this.model = null;\n      }\n      if (this.llama) {\n        await this.llama.dispose();\n        this.llama = null;\n      }\n\n      this.isInitialized = false;\n\n      errorLogger.logError('IntegratedAIService disposed', { type: 'info' });\n    } catch (error) {\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.dispose',\n      });\n    }\n  }\n}\n","usedDeprecatedRules":[{"ruleId":"brace-style","replacedBy":["@stylistic/brace-style"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"brace-style","url":"https://eslint.style/rules/brace-style"}}]}},{"ruleId":"semi","replacedBy":["@stylistic/semi"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"semi","url":"https://eslint.style/rules/semi"}}]}},{"ruleId":"quotes","replacedBy":["@stylistic/quotes"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"quotes","url":"https://eslint.style/rules/quotes"}}]}},{"ruleId":"indent","replacedBy":["@stylistic/indent"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"indent","url":"https://eslint.style/rules/indent"}}]}},{"ruleId":"comma-dangle","replacedBy":["@stylistic/comma-dangle"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"comma-dangle","url":"https://eslint.style/rules/comma-dangle"}}]}},{"ruleId":"no-trailing-spaces","replacedBy":["@stylistic/no-trailing-spaces"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"no-trailing-spaces","url":"https://eslint.style/rules/no-trailing-spaces"}}]}},{"ruleId":"eol-last","replacedBy":["@stylistic/eol-last"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"eol-last","url":"https://eslint.style/rules/eol-last"}}]}},{"ruleId":"object-curly-spacing","replacedBy":["@stylistic/object-curly-spacing"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"object-curly-spacing","url":"https://eslint.style/rules/object-curly-spacing"}}]}},{"ruleId":"array-bracket-spacing","replacedBy":["@stylistic/array-bracket-spacing"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"array-bracket-spacing","url":"https://eslint.style/rules/array-bracket-spacing"}}]}},{"ruleId":"space-before-function-paren","replacedBy":["@stylistic/space-before-function-paren"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"space-before-function-paren","url":"https://eslint.style/rules/space-before-function-paren"}}]}}]}]
