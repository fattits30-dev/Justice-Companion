[{"filePath":"C:\\Users\\sava6\\Desktop\\Justice Companion\\src\\features\\chat\\services\\IntegratedAIService.ts","messages":[{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":52,"column":52,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":52,"endColumn":54,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[1520,1522],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":91,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":91,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":91,"column":30,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":91,"endColumn":33},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":94,"column":18,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":94,"endColumn":20,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[2669,2671],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":110,"column":46,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":110,"endColumn":48,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[3218,3220],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":114,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":118,"endColumn":9},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":114,"column":26,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":114,"endColumn":46},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .loadModel on an `any` value.","line":114,"column":37,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":114,"endColumn":46},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":123,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":123,"endColumn":68},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access ._trainContextSize on an `any` value.","line":123,"column":42,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":123,"endColumn":59},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":123,"column":60,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":123,"endColumn":62,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[3876,3878],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":130,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":130,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[4325,4327],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":138,"column":42,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":138,"endColumn":44,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[4602,4604],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":142,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":145,"endColumn":9},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":142,"column":28,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":142,"endColumn":52},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .createContext on an `any` value.","line":142,"column":39,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":142,"endColumn":52},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":149,"column":25,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":149,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-argument","severity":1,"message":"Unsafe argument of type `any` assigned to a parameter of type `LegalContext`.","line":252,"column":43,"nodeType":"Identifier","messageId":"unsafeArgument","endLine":252,"endColumn":50},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":379,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":379,"endColumn":51},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":379,"column":25,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":379,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .getSequence on an `any` value.","line":379,"column":38,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":379,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":383,"column":9,"nodeType":"Property","messageId":"anyAssignment","endLine":383,"endColumn":24},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":393,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":393,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[13144,13146],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .gpu on an `any` value.","line":401,"column":25,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":401,"endColumn":28},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??=`) instead of an assignment expression, as it is simpler to read.","line":417,"column":11,"nodeType":"IfStatement","messageId":"preferNullishOverAssignment","endLine":419,"endColumn":12,"suggestions":[{"messageId":"suggestNullish","data":{"equals":"="},"fix":{"range":[13929,14012],"text":"firstTokenTime ??= Date.now();"},"desc":"Fix to nullish coalescing operator (`??=`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":435,"column":62,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":435,"endColumn":64,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[14606,14608],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":441,"column":66,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":441,"endColumn":68,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[14826,14828],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":485,"column":13,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":485,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":485,"column":29,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":485,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":499,"column":17,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":499,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":499,"column":33,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":499,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":563,"column":7,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":563,"endColumn":51},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":563,"column":25,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":563,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .getSequence on an `any` value.","line":563,"column":38,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":563,"endColumn":49},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":567,"column":9,"nodeType":"Property","messageId":"anyAssignment","endLine":567,"endColumn":24},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator.","line":575,"column":51,"nodeType":"Punctuator","messageId":"preferNullishOverOr","endLine":575,"endColumn":53,"suggestions":[{"messageId":"suggestNullish","data":{"equals":""},"fix":{"range":[19390,19392],"text":"??"},"desc":"Fix to nullish coalescing operator (`??`)."}]},{"ruleId":"@typescript-eslint/prefer-nullish-coalescing","severity":1,"message":"Prefer using nullish coalescing operator (`??=`) instead of an assignment expression, as it is simpler to read.","line":592,"column":11,"nodeType":"IfStatement","messageId":"preferNullishOverAssignment","endLine":594,"endColumn":12,"suggestions":[{"messageId":"suggestNullish","data":{"equals":"="},"fix":{"range":[20130,20213],"text":"firstTokenTime ??= Date.now();"},"desc":"Fix to nullish coalescing operator (`??=`)."}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":601,"column":13,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":601,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":601,"column":29,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":601,"endColumn":36},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":614,"column":17,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":614,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":614,"column":33,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":614,"endColumn":40},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":654,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":654,"endColumn":35},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":654,"column":28,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":654,"endColumn":35},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":658,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":658,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":658,"column":26,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":658,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":662,"column":15,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":662,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .dispose on an `any` value.","line":662,"column":26,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":662,"endColumn":33}],"suppressedMessages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":38,"column":18,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":38,"endColumn":21,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[908,911],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[908,911],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":39,"column":18,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":39,"endColumn":21,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[970,973],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[970,973],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":40,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":40,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1030,1033],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1030,1033],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":176,"column":42,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":176,"endColumn":45,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5808,5811],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5808,5811],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":360,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":360,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11967,11970],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11967,11970],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":2,"message":"Unexpected any. Specify a different type.","line":531,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":531,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[17879,17882],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[17879,17882],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]}],"errorCount":0,"fatalErrorCount":0,"warningCount":47,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { errorLogger } from '../../../utils/error-logger';\nimport {\n  DEFAULT_AI_CONFIG,\n  buildSystemPrompt,\n  extractSources,\n} from '../../../types/ai';\nimport type {\n  AIConfig,\n  AIStatus,\n  AIChatRequest,\n  AIResponse,\n} from '../../../types/ai';\nimport path from 'path';\nimport { app } from 'electron';\nimport os from 'os';\n\n/**\n * IntegratedAIService - Sovereign AI using node-llama-cpp\n *\n * Runs Qwen 3 8B locally with AMD Vulkan GPU acceleration.\n * No external dependencies - complete sovereignty.\n */\n// Use eslint-disable for node-llama-cpp types (external library with complex types)\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\ninterface CaseFactsRepository {\n  findByCaseId(caseId: number): CaseFact[];\n}\n\ninterface CaseFact {\n  factContent: string;\n  factCategory: string;\n  importance: string;\n}\n\nexport class IntegratedAIService {\n  private config: AIConfig;\n  private llama: any = null; // node-llama-cpp Llama instance\n  private model: any = null; // node-llama-cpp LlamaModel\n  private context: any = null; // node-llama-cpp LlamaContext\n  private isInitialized = false;\n  private modelFileName = 'Qwen_Qwen3-8B-Q4_K_M.gguf';\n  private modelPath: string;\n  private caseFactsRepository: CaseFactsRepository | null = null; // Optional dependency for fact loading\n\n  constructor(config?: Partial<AIConfig>, caseFactsRepository?: CaseFactsRepository) {\n    this.config = {\n      ...DEFAULT_AI_CONFIG,\n      ...config,\n    } as AIConfig;\n\n    this.caseFactsRepository = caseFactsRepository || null;\n\n    // Model storage: app.getPath('userData')/models/\n    const userDataPath = app.getPath('userData');\n    this.modelPath = path.join(userDataPath, 'models', this.modelFileName);\n\n    errorLogger.logError('IntegratedAIService initialized', {\n      type: 'info',\n      modelPath: this.modelPath,\n    });\n  }\n\n  /**\n   * Initialize node-llama-cpp and load Qwen 3 8B model\n   * Uses dynamic import() for ESM compatibility\n   */\n  async initialize(): Promise<void> {\n    if (this.isInitialized) {\n      return;\n    }\n\n    try {\n      errorLogger.logError('Loading node-llama-cpp (ESM dynamic import)', {\n        type: 'info',\n      });\n\n      // Dynamic import for ESM module\n      const { getLlama, LlamaLogLevel } = await import('node-llama-cpp');\n\n      errorLogger.logError('Initializing Llama with AMD GPU detection', {\n        type: 'info',\n      });\n\n      // Initialize with AMD Vulkan GPU auto-detection\n      this.llama = await getLlama({\n        logLevel: LlamaLogLevel.warn,\n      });\n\n      // Log detected GPU\n      const gpu = this.llama.gpu;\n      errorLogger.logError('GPU detected', {\n        type: 'info',\n        gpu: gpu || 'CPU only',\n      });\n\n      errorLogger.logError('Loading Qwen 3 8B model', {\n        type: 'info',\n        modelPath: this.modelPath,\n      });\n\n      // Auto-detect optimal CPU threads (use 75% of available cores for responsiveness)\n      const cpuCores = os.cpus().length;\n      const optimalThreads = this.config.threads ?? Math.max(1, Math.floor(cpuCores * 0.75));\n\n      errorLogger.logError('Hardware auto-detection complete', {\n        type: 'info',\n        cpuCores,\n        optimalThreads,\n        contextSize: this.config.contextSize || 4096,\n      });\n\n      // Load model with AMD GPU acceleration (37/37 layers - full GPU offload for 8GB VRAM)\n      this.model = await this.llama.loadModel({\n        modelPath: this.modelPath,\n        gpuLayers: 'max', // All layers on GPU (8GB VRAM available)\n        defaultContextFlashAttention: true, // Flash Attention for memory efficiency\n      });\n\n      // Auto-detect context size from model capabilities with VRAM awareness\n      // For 8GB VRAM: Model (~4.5GB) + KV cache + overhead = safe limit ~16K tokens\n      // For 16GB+ VRAM: Can use 90% of model's max (29,491 for 32K models)\n      const modelMaxContext = this.model._trainContextSize || 32768;\n\n      // Conservative context for 8GB VRAM (tested on AMD RX 6600 8GB)\n      // This ensures model + KV cache fit comfortably in VRAM\n      // Tested: 16K failed (VRAM overflow), 12K works perfectly\n      const safeContextFor8GB = 12288; // 12K tokens = ~9,000 words (ideal for legal documents)\n      const optimalContext = Math.min(safeContextFor8GB, Math.floor(modelMaxContext * 0.9));\n      const contextSize = this.config.contextSize || optimalContext;\n\n      errorLogger.logError(`Creating context (${contextSize} tokens with Flash Attention)`, {\n        type: 'info',\n        modelMaxContext,\n        optimalContext,\n        contextSize,\n        flashAttention: true,\n        batchSize: this.config.batchSize || 'auto',\n      });\n\n      // Create context for legal document analysis with Flash Attention\n      this.context = await this.model.createContext({\n        contextSize, // Auto-detected from model (90% of 32,768 = 29,491 tokens)\n        ...(this.config.batchSize && { batchSize: this.config.batchSize }), // Optional batch size optimization\n      });\n\n      errorLogger.logError('IntegratedAIService fully initialized', {\n        type: 'info',\n        gpu: this.llama.gpu,\n        cpuCores,\n        threads: optimalThreads,\n        contextSize,\n        flashAttention: true,\n        gpuLayers: '37/37 (max)',\n      });\n\n      this.isInitialized = true;\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      this.isInitialized = false;\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.initialize',\n      });\n\n      throw new Error(`Failed to initialize Integrated AI: ${errorMessage}`);\n    }\n  }\n\n  /**\n   * Get Qwen 3 optimized system prompt with fact-gathering rules\n   * Qwen 3 supports <think> tags for reasoning and [[call: function()]] for tool use\n   */\n  private getQwen3SystemPrompt(context?: any, facts?: CaseFact[]): string {\n    // Build base prompt with fact-gathering rules\n    const basePrompt = `You are a UK legal information assistant with ADMINISTRATIVE POWERS.\n\n🔒 HARD-CODED RULES (NEVER BREAK):\n\nRULE 0: FIRST-TIME USER ONBOARDING (HIGHEST PRIORITY)\n- If user responds to welcome questions with personal info or their issue:\n  ✓ Extract name/email and call update_user_profile immediately\n  ✓ Extract issue description and store as case fact using store_case_fact\n  ✓ Thank them warmly for sharing their situation\n  ✓ Ask 2-3 specific follow-up questions to gather MORE details about their case\n- Example: User says \"My name is John and I was unfairly dismissed\"\n  → Call: update_user_profile({name: \"John\"})\n  → Call: store_case_fact({factType: \"issue\", factKey: \"case_type\", factValue: \"unfair dismissal\", confidence: 1.0})\n  → Respond: \"Thank you for sharing, John. I'm here to help with your dismissal case. Can you tell me: when did this happen, who was your employer, and did you receive any written notice?\"\n\nRULE 1: FACT-GATHERING IS MANDATORY\n- When working on a case with <3 stored facts, you are in FACT-GATHERING MODE\n- You MUST gather these facts BEFORE providing legal information:\n  ✓ Party names (employee, employer, witnesses)\n  ✓ Key dates (employment start, dismissal date, deadlines)\n  ✓ Event sequence (what happened, when, why)\n  ✓ Evidence available (contracts, emails, witnesses)\n\nRULE 2: STORE FACTS IMMEDIATELY\n- As user provides information, extract facts and store them using store_case_fact\n- Format: [[call: store_case_fact({caseId: 42, factType: \"timeline\", factKey: \"dismissal_date\", factValue: \"2024-01-15\", confidence: 1.0})]]\n- Store facts for: parties (witness), dates (timeline), events (timeline), evidence (evidence), locations (location), communications (communication)\n\nRULE 3: FACTS ARE YOUR ANCHOR\n- Before EVERY response about a case, load facts using get_case_facts\n- Format: [[call: get_case_facts({caseId: 42})]]\n- Reference specific stored facts in your response to show you remember\n\nREASONING INSTRUCTIONS:\n- Use <think>reasoning</think> tags for complex analysis\n- Inside <think>: analyze question, check facts, plan response\n- User will NOT see <think> content\n\nEMPATHETIC COMMUNICATION:\n- Acknowledge their situation warmly\n- Use supportive phrases: \"I understand this must be...\", \"That's a great question...\"\n- Be conversational, not clinical\n- Validate concerns before explaining law\n\nPROFESSIONAL STANDARDS:\n- Provide legal INFORMATION, NOT legal advice\n- Cite sources precisely (e.g., \"Employment Rights Act 1996 Section 94\")\n- Ask clarifying questions if needed\n- Never give blunt \"I don't have information\"\n\nTONE EXAMPLES:\n✓ \"I understand this is stressful. Let me explain unfair dismissal law...\"\n✓ \"Great question. The Employment Rights Act 1996 states...\"\n✗ \"Query processed. ERA 1996 S94 states...\"\n✗ \"I don't have that information.\"\n\nFormat for citations:\n- Legislation: \"Section X of the [Act Name] [Year]\"\n- Case law: \"[Case Name] [Year] [Court]\"`;\n\n    // If we have stored facts, append them to the prompt\n    if (facts && facts.length > 0) {\n      const factsSection = `\n\n📋 STORED FACTS FOR THIS CASE:\n${facts.map((f) => `- ${f.factContent} [${f.factCategory}, ${f.importance} importance]`).join('\\n')}\n\nUse these facts as your memory. Reference them in your responses.`;\n\n      return basePrompt + factsSection;\n    }\n\n    // If we have RAG context, use buildSystemPrompt but inject fact-gathering rules\n    if (context) {\n      const ragPrompt = buildSystemPrompt(context);\n      // Prepend fact-gathering rules to RAG prompt\n      return basePrompt + '\\n\\n--- RAG CONTEXT ---\\n' + ragPrompt;\n    }\n\n    return basePrompt;\n  }\n\n  /**\n   * Check if Integrated AI is ready\n   */\n  async checkConnection(): Promise<AIStatus> {\n    try {\n      // If not initialized, try to initialize\n      if (!this.isInitialized) {\n        await this.initialize();\n      }\n\n      return {\n        connected: true,\n        endpoint: 'Integrated AI (Qwen 3 8B)',\n        model: this.modelFileName,\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      return {\n        connected: false,\n        endpoint: 'Integrated AI (Qwen 3 8B)',\n        error: errorMessage,\n      };\n    }\n  }\n\n  /**\n   * Non-streaming chat (converts streaming to single response)\n   */\n  async chat(request: AIChatRequest): Promise<AIResponse> {\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n      if (!status.connected) {\n        return {\n          success: false,\n          error: `Integrated AI not ready: ${status.error}`,\n          code: 'INTEGRATED_AI_OFFLINE',\n        };\n      }\n\n      let fullResponse = '';\n      const sources: string[] = [];\n\n      // Use streaming internally\n      await this.streamChat(\n        request,\n        (token) => {\n          fullResponse += token;\n        },\n        () => {\n          // Complete\n        },\n        (error) => {\n          throw new Error(error);\n        },\n        undefined, // No think tokens needed for non-streaming\n        (extractedSources) => {\n          sources.push(...extractedSources);\n        },\n      );\n\n      return {\n        success: true,\n        message: {\n          role: 'assistant',\n          content: fullResponse,\n          timestamp: new Date().toISOString(),\n        },\n        sources,\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.chat',\n      });\n\n      return {\n        success: false,\n        error: errorMessage,\n        code: 'EXCEPTION',\n      };\n    }\n  }\n\n  /**\n   * Streaming chat with Qwen 3 8B\n   * Maintains exact same interface as AIService\n   */\n  async streamChat(\n    request: AIChatRequest,\n    onToken: (token: string) => void,\n    onComplete: () => void,\n    onError: (error: string) => void,\n    onThinkToken?: (token: string) => void,\n    onSources?: (sources: string[]) => void,\n  ): Promise<void> {\n    let contextSequence: any = null; // node-llama-cpp LlamaContextSequence\n\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n\n      if (!status.connected) {\n        onError(`Integrated AI not ready: ${status.error}`);\n        return;\n      }\n\n      // Import session class\n      const { LlamaChatSession } = await import('node-llama-cpp');\n\n      // Build system prompt\n      const systemPrompt = this.getQwen3SystemPrompt(request.context);\n\n      // Create FRESH sequence that will be disposed after use\n      // This prevents KV cache accumulation and VRAM overflow\n      contextSequence = this.context.getSequence();\n\n      // Create chat session with fresh sequence\n      const chatSession = new LlamaChatSession({\n        contextSequence,\n        systemPrompt,\n      });\n\n      // Get ONLY the most recent user message (not full history)\n      // UI maintains conversation history - we just process latest question\n      // This keeps context size constant: system prompt + latest question\n      const lastUserMessage = [...request.messages]\n        .reverse()\n        .find((msg) => msg.role === 'user');\n      const userPrompt = lastUserMessage?.content || '';\n\n      if (!userPrompt) {\n        throw new Error('No user message found in request');\n      }\n\n      errorLogger.logError('Starting Qwen 3 8B streaming inference', {\n        type: 'info',\n        gpu: this.llama.gpu,\n      });\n\n      let accumulatedContent = '';\n      let insideThinkTag = false;\n      let thinkBuffer = '';\n      let tokenCount = 0;\n      const startTime = Date.now();\n      let firstTokenTime: number | null = null;\n\n      // Stream tokens\n      await chatSession.prompt(userPrompt.trim(), {\n        temperature: request.config?.temperature ?? this.config.temperature,\n        maxTokens: request.config?.maxTokens ?? this.config.maxTokens,\n        onTextChunk: (chunk: string) => {\n          // Record time of first token (after prompt processing)\n          if (firstTokenTime === null) {\n            firstTokenTime = Date.now();\n          }\n\n          tokenCount++;\n          // Process chunk for <think> tag filtering\n          thinkBuffer += chunk;\n\n          // Check for tag transitions\n          if (thinkBuffer.includes('<think>')) {\n            insideThinkTag = true;\n            // Extract content before tag and send it\n            const beforeTag = thinkBuffer.split('<think>')[0];\n            if (beforeTag) {\n              onToken(beforeTag);\n              accumulatedContent += beforeTag;\n            }\n            // Keep content after tag for next iteration\n            thinkBuffer = thinkBuffer.split('<think>').pop() || '';\n          }\n\n          if (thinkBuffer.includes('</think>')) {\n            insideThinkTag = false;\n            // Extract content after closing tag\n            const afterTag = thinkBuffer.split('</think>').pop() || '';\n            thinkBuffer = afterTag;\n          }\n\n          // Send token based on context\n          if (insideThinkTag) {\n            // Send think content to onThinkToken callback if provided\n            if (thinkBuffer && onThinkToken) {\n              onThinkToken(thinkBuffer);\n              thinkBuffer = '';\n            }\n          } else if (thinkBuffer) {\n            // Send display content to onToken callback\n            onToken(thinkBuffer);\n            accumulatedContent += thinkBuffer;\n            thinkBuffer = '';\n          }\n        },\n      });\n\n      // Calculate performance stats\n      const endTime = Date.now();\n      const totalDuration = (endTime - startTime) / 1000;\n      const generationTime = firstTokenTime ? (endTime - firstTokenTime) / 1000 : totalDuration;\n      const generationSpeed = generationTime > 0 ? tokenCount / generationTime : 0;\n\n      // Extract sources after completion\n      if (request.context && onSources && accumulatedContent) {\n        const sources = extractSources(accumulatedContent, request.context);\n        errorLogger.logError('Sources extracted from Qwen 3 response', {\n          type: 'info',\n          sourcesCount: sources.length,\n        });\n        onSources(sources);\n      }\n\n      errorLogger.logError('Qwen 3 8B streaming complete', {\n        type: 'info',\n        tokenCount,\n        totalDuration: totalDuration.toFixed(2),\n        generationSpeed: generationSpeed.toFixed(2),\n      });\n\n      // CRITICAL: Dispose sequence to clear KV cache and prevent VRAM accumulation\n      await contextSequence.dispose();\n\n      onComplete();\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.streamChat',\n      });\n\n      // Clean up sequence even on error (if it was created)\n      if (contextSequence) {\n        try {\n          await contextSequence.dispose();\n        } catch (disposeError) {\n          errorLogger.logError(disposeError as Error, {\n            context: 'Failed to dispose sequence after error',\n          });\n        }\n      }\n\n      onError(errorMessage);\n    }\n  }\n\n  /**\n   * Streaming chat with Qwen 3 8B + Function Calling\n   *\n   * This method enables AI to call functions like store_case_fact and get_case_facts.\n   * Uses node-llama-cpp's built-in function calling with LlamaChatSession.\n   * Functions are automatically executed when AI uses [[call: function()]] syntax.\n   *\n   * @param request - Chat request with messages and context\n   * @param caseId - Optional case ID for fact loading/storing\n   * @param onToken - Callback for each token generated\n   * @param onComplete - Callback when streaming completes\n   * @param onError - Callback for errors\n   */\n  async streamChatWithFunctions(\n    request: AIChatRequest,\n    caseId: number | undefined,\n    onToken: (token: string) => void,\n    onComplete: () => void,\n    onError: (error: string) => void,\n  ): Promise<void> {\n    let contextSequence: any = null; // node-llama-cpp LlamaContextSequence\n\n    try {\n      // Ensure initialized\n      const status = await this.checkConnection();\n      if (!status.connected) {\n        onError(`Integrated AI not ready: ${status.error}`);\n        return;\n      }\n\n      // Load facts if caseId provided (for system prompt injection)\n      let facts: CaseFact[] = [];\n      if (caseId && this.caseFactsRepository) {\n        try {\n          facts = this.caseFactsRepository.findByCaseId(caseId);\n        } catch (error) {\n          errorLogger.logError(error as Error, {\n            context: 'Failed to load facts for AI context',\n            caseId,\n          });\n          // Continue with empty facts - don't fail the entire request\n        }\n      }\n\n      // Import required classes\n      const { LlamaChatSession } = await import('node-llama-cpp');\n      const { aiFunctions } = await import('../../../services/ai-functions.js');\n\n      // Build system prompt with facts\n      const systemPrompt = this.getQwen3SystemPrompt(request.context, facts);\n\n      // Create fresh sequence\n      contextSequence = this.context.getSequence();\n\n      // Create chat session with function calling enabled\n      const chatSession = new LlamaChatSession({\n        contextSequence,\n        systemPrompt,\n      });\n\n      // Get only the most recent user message\n      const lastUserMessage = [...request.messages]\n        .reverse()\n        .find((msg) => msg.role === 'user');\n      const userPrompt = lastUserMessage?.content || '';\n\n      if (!userPrompt) {\n        throw new Error('No user message found in request');\n      }\n\n      let _tokenCount = 0;\n      let firstTokenTime: number | null = null;\n\n      // Stream with function calling enabled\n      // Note: node-llama-cpp automatically executes functions when AI uses [[call: function()]] syntax\n      // Function results are automatically sent back to AI as [[result: {...}]]\n      await chatSession.prompt(userPrompt.trim(), {\n        temperature: request.config?.temperature ?? this.config.temperature,\n        maxTokens: request.config?.maxTokens ?? this.config.maxTokens,\n        functions: aiFunctions, // 🔥 Enable function calling (auto-executed)\n        onTextChunk: (chunk: string) => {\n          if (firstTokenTime === null) {\n            firstTokenTime = Date.now();\n          }\n          _tokenCount++;\n          onToken(chunk);\n        },\n      });\n\n      // Dispose sequence\n      await contextSequence.dispose();\n\n      onComplete();\n    } catch (error) {\n      const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.streamChatWithFunctions',\n      });\n\n      // Clean up sequence on error\n      if (contextSequence) {\n        try {\n          await contextSequence.dispose();\n        } catch (disposeError) {\n          errorLogger.logError(disposeError as Error, {\n            context: 'Failed to dispose sequence after error in streamChatWithFunctions',\n          });\n        }\n      }\n\n      onError(errorMessage);\n    }\n  }\n\n  /**\n   * Update configuration\n   */\n  updateConfig(config: Partial<AIConfig>): void {\n    this.config = {\n      ...this.config,\n      ...config,\n    };\n\n    errorLogger.logError('Integrated AI configuration updated', {\n      type: 'info',\n      config: this.config,\n    });\n  }\n\n  /**\n   * Get current configuration\n   */\n  getConfig(): AIConfig {\n    return { ...this.config };\n  }\n\n  /**\n   * Cleanup resources\n   */\n  async dispose(): Promise<void> {\n    try {\n      if (this.context) {\n        await this.context.dispose();\n        this.context = null;\n      }\n      if (this.model) {\n        await this.model.dispose();\n        this.model = null;\n      }\n      if (this.llama) {\n        await this.llama.dispose();\n        this.llama = null;\n      }\n\n      this.isInitialized = false;\n\n      errorLogger.logError('IntegratedAIService disposed', { type: 'info' });\n    } catch (error) {\n      errorLogger.logError(error as Error, {\n        context: 'IntegratedAIService.dispose',\n      });\n    }\n  }\n}\n","usedDeprecatedRules":[{"ruleId":"brace-style","replacedBy":["@stylistic/brace-style"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"brace-style","url":"https://eslint.style/rules/brace-style"}}]}},{"ruleId":"semi","replacedBy":["@stylistic/semi"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"semi","url":"https://eslint.style/rules/semi"}}]}},{"ruleId":"quotes","replacedBy":["@stylistic/quotes"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"quotes","url":"https://eslint.style/rules/quotes"}}]}},{"ruleId":"indent","replacedBy":["@stylistic/indent"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"indent","url":"https://eslint.style/rules/indent"}}]}},{"ruleId":"comma-dangle","replacedBy":["@stylistic/comma-dangle"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"comma-dangle","url":"https://eslint.style/rules/comma-dangle"}}]}},{"ruleId":"no-trailing-spaces","replacedBy":["@stylistic/no-trailing-spaces"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"no-trailing-spaces","url":"https://eslint.style/rules/no-trailing-spaces"}}]}},{"ruleId":"eol-last","replacedBy":["@stylistic/eol-last"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"eol-last","url":"https://eslint.style/rules/eol-last"}}]}},{"ruleId":"object-curly-spacing","replacedBy":["@stylistic/object-curly-spacing"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"object-curly-spacing","url":"https://eslint.style/rules/object-curly-spacing"}}]}},{"ruleId":"array-bracket-spacing","replacedBy":["@stylistic/array-bracket-spacing"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"array-bracket-spacing","url":"https://eslint.style/rules/array-bracket-spacing"}}]}},{"ruleId":"space-before-function-paren","replacedBy":["@stylistic/space-before-function-paren"],"info":{"message":"Formatting rules are being moved out of ESLint core.","url":"https://eslint.org/blog/2023/10/deprecating-formatting-rules/","deprecatedSince":"8.53.0","availableUntil":"11.0.0","replacedBy":[{"message":"ESLint Stylistic now maintains deprecated stylistic core rules.","url":"https://eslint.style/guide/migration","plugin":{"name":"@stylistic/eslint-plugin","url":"https://eslint.style"},"rule":{"name":"space-before-function-paren","url":"https://eslint.style/rules/space-before-function-paren"}}]}}]}]
