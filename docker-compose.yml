# Docker Compose for Justice Companion
# Optional: Use this when you need backend services

version: '3.8'

services:
  # Redis cache for Legal API responses
  redis:
    image: redis:7-alpine
    container_name: justice-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

  # LM Studio compatible AI service (when needed)
  # localai:
  #   image: localai/localai:latest-aio-cpu
  #   container_name: justice-ai
  #   ports:
  #     - "1234:1234"
  #   volumes:
  #     - ./ai-models:/models
  #   environment:
  #     - THREADS=4
  #     - CONTEXT_SIZE=2048
  #   restart: unless-stopped

  # Development environment (optional - use dev containers instead)
  # dev:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.dev
  #   container_name: justice-dev
  #   volumes:
  #     - .:/app
  #     - /app/node_modules
  #   ports:
  #     - "5173:5173"  # Vite dev server
  #     - "5555:5555"  # MCP dev API
  #   depends_on:
  #     - redis
  #   environment:
  #     - NODE_ENV=development
  #   restart: unless-stopped

volumes:
  redis-data:
    driver: local

networks:
  default:
    name: justice-network
