# Justice Companion AI Service Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Service Configuration
# =============================================================================

# Server settings
HOST=127.0.0.1
PORT=5051
ENVIRONMENT=development  # development|production

# Development settings
RELOAD=true  # Enable auto-reload in development

# =============================================================================
# AI Model Configuration
# =============================================================================

# Model Selection Priority:
# 1. USE_LOCAL_MODELS=true (best privacy, free, requires GPU/CPU)
# 2. HF_TOKEN (Pro subscription, £9/month, good privacy)
# 3. OPENAI_API_KEY (paid, less private)

# Use local HuggingFace models (requires significant RAM/GPU)
USE_LOCAL_MODELS=false

# HuggingFace API Token (£9/month subscription)
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=

# OpenAI API Key (fallback option, charges apply)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# =============================================================================
# Model Configuration
# =============================================================================

# Local model settings (when USE_LOCAL_MODELS=true)
MODEL_NAME=google/flan-t5-large  # Local model to use
MAX_TOKENS=2000
TEMPERATURE=0.7

# HuggingFace API model (when HF_TOKEN provided)
HF_MODEL=Qwen/Qwen3-30B-A3B-Instruct-2507  # £9/month Pro model

# OpenAI model (when OPENAI_API_KEY provided)
OPENAI_MODEL=gpt-3.5-turbo

# =============================================================================
# Performance & Caching
# =============================================================================

# Model cache directory (Docker volume mounted)
TRANSFORMERS_CACHE=./models_cache
HF_HOME=./models_cache
TORCH_HOME=./models_cache

# Enable CPU optimization (slower but uses less RAM)
USE_CPU_OPTIMIZATION=false

# =============================================================================
# Security & Safety
# =============================================================================

# API Rate limiting
MAX_REQUESTS_PER_MINUTE=60
BURST_LIMIT=20

# File upload limits
MAX_FILE_SIZE=10485760  # 10MB in bytes
ALLOWED_EXTENSIONS=jpg,jpeg,png,bmp,tiff,tif,heic,pdf

# Request timeouts (seconds)
REQUEST_TIMEOUT=300  # 5 minutes for AI processing

# =============================================================================
# Logging & Monitoring
# =============================================================================

# Log level
LOG_LEVEL=INFO  # DEBUG|INFO|WARNING|ERROR

# Enable performance logging
PERFORMANCE_LOGGING=true

# =============================================================================
# CORS Configuration (for development)
# =============================================================================

# Allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:5176,http://localhost:5173,http://127.0.0.1:5176,http://127.0.0.1:5173

# =============================================================================
# Health Check Configuration
# =============================================================================

# Enable detailed health checks
HEALTH_CHECKS_ENABLED=true

# Health check model (small model for quick validation)
HEALTH_CHECK_MODEL=sentence-transformers/all-MiniLM-L6-v2

# =============================================================================
# OCR Configuration
# =============================================================================

# Tesseract OCR language (comma-separated)
TESSERACT_LANGUAGES=eng

# OCR confidence threshold (0-100)
OCR_CONFIDENCE_THRESHOLD=60

# Maximum OCR retries
OCR_MAX_RETRIES=2

# =============================================================================
# Example Production Configuration
# =============================================================================
# For production deployment, set these values:

# ENVIRONMENT=production
# RELOAD=false
# HF_TOKEN=your_huggingface_token_here
# USE_LOCAL_MODELS=false
# LOG_LEVEL=WARNING
# MAX_REQUESTS_PER_MINUTE=100
